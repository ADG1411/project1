# MLOps Infrastructure Validation Pipeline
name: MLOps Infrastructure Validation

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Daily validation at 2 AM UTC
    - cron: '0 2 * * *'

env:
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  # Configuration Validation
  config-validation:
    name: Configuration Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install validation tools
      run: |
        pip install --upgrade pip
        pip install yamllint jsonschema pyhcl2 requests
        
    - name: Validate YAML files
      run: |
        echo "Validating YAML configuration files..."
        yamllint --config-file .yamllint.yml docker-compose.yml
        yamllint --config-file .yamllint.yml prometheus/prometheus.yml
        yamllint --config-file .yamllint.yml grafana/datasources.yml
        yamllint --config-file .yamllint.yml grafana/dashboards.yml
        
    - name: Validate JSON files
      run: |
        echo "Validating JSON configuration files..."
        python -m json.tool grafana/dashboard.json > /dev/null
        echo "âœ“ JSON files are valid"
        
    - name: Validate HCL files
      run: |
        echo "Validating HCL configuration files..."
        python -c "
        import hcl2
        import json
        
        # Validate Consul configuration
        with open('consul/consul.hcl', 'r') as f:
            consul_config = hcl2.load(f)
            print('âœ“ Consul HCL is valid')
        
        # Validate Nomad configuration
        with open('nomad/nomad.hcl', 'r') as f:
            nomad_config = hcl2.load(f)
            print('âœ“ Nomad HCL is valid')
            
        # Validate Nomad job
        with open('nomad/mlops.nomad', 'r') as f:
            nomad_job = hcl2.load(f)
            print('âœ“ Nomad job HCL is valid')
        "
        
    - name: Validate Docker Compose
      run: |
        echo "Validating Docker Compose configuration..."
        docker-compose config --quiet
        echo "âœ“ Docker Compose configuration is valid"
        
    - name: Validate environment variables
      run: |
        echo "Validating environment variable configuration..."
        python scripts/validate_env.py
        
    - name: Configuration schema validation
      run: |
        echo "Running custom configuration validation..."
        python validate_config.py

  # Security Scanning
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Run Trivy filesystem scan
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        
    - name: Upload Trivy results to GitHub Security
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'
        
    - name: Run Hadolint (Dockerfile linter)
      uses: hadolint/hadolint-action@v3.1.0
      with:
        dockerfile: app/Dockerfile
        format: sarif
        output-file: hadolint-results.sarif
        
    - name: Upload Hadolint results
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: hadolint-results.sarif
        
    - name: Check for secrets
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: main
        head: HEAD
        extra_args: --debug --only-verified

  # Python Application Testing
  python-tests:
    name: Python Application Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        cd app
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black bandit safety
        
    - name: Code formatting check
      run: |
        cd app
        black --check --diff .
        
    - name: Linting
      run: |
        cd app
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Security scan
      run: |
        cd app
        bandit -r . -f json -o bandit-report.json
        safety check --json --output safety-report.json
      continue-on-error: true
      
    - name: Unit tests
      run: |
        cd app
        pytest tests/ -v --cov=. --cov-report=xml --cov-report=html
        
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./app/coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Docker Image Building and Scanning
  docker-build-scan:
    name: Docker Build and Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Build ML Training image
      uses: docker/build-push-action@v5
      with:
        context: ./app
        file: ./app/Dockerfile
        push: false
        tags: mlops-trainer:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Run Trivy vulnerability scanner on image
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'mlops-trainer:${{ github.sha }}'
        format: 'sarif'
        output: 'trivy-image-results.sarif'
        
    - name: Upload Trivy image results
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-image-results.sarif'
        
    - name: Test image functionality
      run: |
        echo "Testing Docker image functionality..."
        docker run --rm \
          -e MODEL_NAME=test-model \
          -e TRAINING_EPOCHS=2 \
          mlops-trainer:${{ github.sha }}

  # Infrastructure Testing
  infrastructure-test:
    name: Infrastructure Integration Test
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    services:
      docker:
        image: docker:24-dind
        options: --privileged
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Create test environment file
      run: |
        cat > .env << EOF
        GRAFANA_ADMIN_PASSWORD=test-password-123
        EOF
        
    - name: Start infrastructure
      run: |
        echo "Starting MLOps infrastructure..."
        docker-compose up -d --build
        
    - name: Wait for services to be healthy
      run: |
        echo "Waiting for services to start..."
        timeout 300 bash -c '
        while true; do
          if docker-compose ps | grep -q "Up (healthy).*consul" && \
             docker-compose ps | grep -q "Up (healthy).*prometheus" && \
             docker-compose ps | grep -q "Up (healthy).*grafana"; then
            echo "All services are healthy"
            break
          fi
          echo "Waiting for services to be healthy..."
          sleep 10
        done'
        
    - name: Test service endpoints
      run: |
        echo "Testing service endpoints..."
        
        # Test Consul
        curl -f http://localhost:8500/v1/status/leader
        echo "âœ“ Consul is responding"
        
        # Test Nomad  
        curl -f http://localhost:4646/v1/status/leader
        echo "âœ“ Nomad is responding"
        
        # Test Prometheus
        curl -f http://localhost:9090/-/healthy
        echo "âœ“ Prometheus is responding"
        
        # Test Grafana
        curl -f http://localhost:3000/api/health
        echo "âœ“ Grafana is responding"
        
        # Test Pushgateway
        curl -f http://localhost:9091/-/healthy
        echo "âœ“ Pushgateway is responding"
        
    - name: Test Nomad job submission
      run: |
        echo "Testing Nomad job submission..."
        
        # Wait for Nomad to be ready
        sleep 30
        
        # Submit test job
        curl -X POST \
          -H "Content-Type: application/json" \
          -d '{"Job": {"ID": "test-job", "Name": "test-job", "Type": "batch", "Datacenters": ["mlops-dc1"], "TaskGroups": [{"Name": "test", "Count": 1, "Tasks": [{"Name": "test-task", "Driver": "docker", "Config": {"image": "alpine:latest", "command": "echo", "args": ["Hello from Nomad"]}}]}]}}' \
          http://localhost:4646/v1/jobs
        
        echo "âœ“ Nomad job submitted successfully"
        
    - name: Test metric submission
      run: |
        echo "Testing metric submission to Pushgateway..."
        
        # Submit test metric
        echo 'test_metric{job="ci-test"} 42' | curl --data-binary @- \
          http://localhost:9091/metrics/job/ci-test/instance/test
        
        # Verify metric was received
        curl -s http://localhost:9091/metrics | grep -q "test_metric"
        echo "âœ“ Metrics submission working"
        
    - name: Collect logs on failure
      if: failure()
      run: |
        echo "Collecting container logs..."
        mkdir -p logs
        docker-compose logs consul > logs/consul.log
        docker-compose logs nomad > logs/nomad.log
        docker-compose logs prometheus > logs/prometheus.log
        docker-compose logs grafana > logs/grafana.log
        
    - name: Upload logs
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: container-logs
        path: logs/
        
    - name: Cleanup
      if: always()
      run: |
        docker-compose down -v
        docker system prune -af

  # Performance Testing
  performance-test:
    name: Performance Testing
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Install k6
      run: |
        sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
        
    - name: Start infrastructure
      run: |
        cat > .env << EOF
        GRAFANA_ADMIN_PASSWORD=test-password-123
        EOF
        docker-compose up -d
        
    - name: Wait for services
      run: |
        sleep 60
        
    - name: Run performance tests
      run: |
        k6 run --out json=performance-results.json tests/performance/load-test.js
        
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      with:
        name: performance-results
        path: performance-results.json

  # Documentation Validation
  documentation-check:
    name: Documentation Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Check documentation completeness
      run: |
        echo "Checking documentation completeness..."
        
        # Check required documentation files exist
        files=(
          "README.md"
          "ARCHITECTURE.md" 
          "DEPLOYMENT_CHECKLIST.md"
          "BACKUP_PROCEDURES.md"
          "HA_ARCHITECTURE.md"
          "TLS_SSL_CONFIG.md"
        )
        
        for file in "${files[@]}"; do
          if [ ! -f "$file" ]; then
            echo "ERROR: Required documentation file missing: $file"
            exit 1
          else
            echo "âœ“ Found: $file"
          fi
        done
        
    - name: Validate Markdown
      uses: DavidAnson/markdownlint-cli2-action@v13
      with:
        globs: '**/*.md'
        
    - name: Check for broken links
      uses: gaurav-nelson/github-action-markdown-link-check@v1
      with:
        use-quiet-mode: 'yes'
        use-verbose-mode: 'yes'
        config-file: '.markdown-link-check.json'

  # Deployment Readiness Check
  deployment-readiness:
    name: Deployment Readiness Check
    runs-on: ubuntu-latest
    needs: [config-validation, security-scan, python-tests, docker-build-scan, infrastructure-test]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Run pre-deployment validation
      run: |
        echo "Running pre-deployment validation..."
        python pre_deployment_check.py
        
    - name: Generate deployment report
      run: |
        echo "Generating deployment readiness report..."
        cat > deployment-report.md << EOF
        # Deployment Readiness Report
        
        **Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
        **Commit:** ${{ github.sha }}
        **Branch:** ${{ github.ref_name }}
        
        ## Validation Results
        - âœ… Configuration validation passed
        - âœ… Security scanning passed
        - âœ… Python tests passed
        - âœ… Docker build and scan passed
        - âœ… Infrastructure integration tests passed
        
        ## Deployment Status
        ðŸŸ¢ **READY FOR DEPLOYMENT**
        
        All validation checks have passed. The MLOps infrastructure is ready for deployment.
        EOF
        
    - name: Upload deployment report
      uses: actions/upload-artifact@v3
      with:
        name: deployment-report
        path: deployment-report.md

  # Notification
  notify:
    name: Notification
    runs-on: ubuntu-latest
    needs: [config-validation, security-scan, python-tests, docker-build-scan, infrastructure-test, documentation-check]
    if: always()
    
    steps:
    - name: Notify on success
      if: ${{ needs.config-validation.result == 'success' && needs.security-scan.result == 'success' && needs.python-tests.result == 'success' && needs.docker-build-scan.result == 'success' && needs.infrastructure-test.result == 'success' && needs.documentation-check.result == 'success' }}
      run: |
        echo "ðŸŽ‰ All validation checks passed successfully!"
        
    - name: Notify on failure
      if: ${{ needs.config-validation.result == 'failure' || needs.security-scan.result == 'failure' || needs.python-tests.result == 'failure' || needs.docker-build-scan.result == 'failure' || needs.infrastructure-test.result == 'failure' || needs.documentation-check.result == 'failure' }}
      run: |
        echo "âŒ One or more validation checks failed. Please review the results."
        exit 1